# ğŸ§  AI Doc Bot â€“ Medical Chatbot with Voice & Vision Capabilities

**AI Doc Bot** is a multimodal medical chatbot designed to assist in basic health consultations.  
It can **see**, **listen**, and **speak** â€” combining **vision**, **voice**, and **language understanding** through advanced AI models.

---

## ğŸš€ Features

- ğŸ©º **Multimodal AI** â€“ Understands text, images (like medical scans), and voice inputs.
- ğŸ—£ï¸ **Voice Interaction** â€“ Patients can talk naturally; the bot listens and responds in voice.
- ğŸ‘ï¸ **Vision Capabilities** â€“ Uses vision models to analyze medical images.
- ğŸ’¬ **Interactive UI** â€“ Built with **Gradio** for a seamless chat interface.
- âš™ï¸ **Modular Architecture** â€“ Clear separation between AI, voice, and UI components.

---

## ğŸ§© Project Architecture

### **Phase 1 â€“ Brain of the Doctor**
- Configure **GROQ API** for AI inference.
- Preprocess medical images for vision model input.
- Integrate **Multimodal LLM** (e.g., LLaMA 3 Vision).

### **Phase 2 â€“ Voice of the Patient**
- Use **FFmpeg** and **PortAudio** for audio recording.
- Implement **Speech-to-Text (STT)** with **OpenAI Whisper**.

### **Phase 3 â€“ Voice of the Doctor**
- Use **Text-to-Speech (TTS)** engines like **gTTS** and **ElevenLabs**.
- Convert text replies from the AI into spoken responses.

### **Phase 4 â€“ User Interface**
- Create an easy-to-use **VoiceBot UI** using **Gradio**.

---

## ğŸ§° Tools & Technologies

| Category | Technology |
|-----------|-------------|
| **AI Inference** | GROQ |
| **Vision Model** | LLaMA 3 Vision (Meta) |
| **Speech-to-Text** | OpenAI Whisper |
| **Text-to-Speech** | gTTS, ElevenLabs |
| **UI Framework** | Gradio |
| **Language** | Python |
| **IDE** | VS Code |

---

## ğŸ§± System Workflow

```
Patient Voice/Image
        â†“
 [STT â€“ Whisper]
        â†“
 [Multimodal LLM â€“ LLaMA 3 Vision via GROQ]
        â†“
 [TTS â€“ gTTS / ElevenLabs]
        â†“
Doctorâ€™s Voice Response
```

---

## ğŸ’¡ Future Enhancements

- Integrate **paid LLMs** for advanced reasoning.
- **Fine-tune vision models** using real medical datasets.
- Add **multilingual support** for wider reach.
- Include **medical report summarization** and **diagnostic support**.

---

## âš™ï¸ Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/Ashwin007-ai/AI_Doc_Bot-voice_vision.git
   cd AI_Doc_Bot-voice_vision
   ```

2. **Create and activate a virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate    # (Linux/macOS)
   venv\Scripts\activate       # (Windows)
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Add your API keys**
   ```bash
   export GROQ_API_KEY=your_key_here
   ```

5. **Run the application**
   ```bash
   python gradio_app.py
   ```

Open the local Gradio link displayed in your terminal to interact with the AI Doc Bot.

---

## ğŸ§ª Example Use Case

1. Speak or upload an image describing your symptoms.  
2. The AI processes your input using **Whisper + LLaMA 3 Vision**.  
3. The AI Doctor responds with a **voice reply** generated using **gTTS / ElevenLabs**.

---

## ğŸ‘¨â€ğŸ’» Project Info

- **Project Name:** AI Doc Bot  
- **Created By:** P Ashwin Kumar  
- **Core Technologies:** Python, Whisper, LLaMA 3 Vision, GROQ, Gradio, ElevenLabs  

---

## ğŸ“œ License

This project is licensed under the **MIT License**.  
You are free to use, modify, and distribute it for learning or research purposes.

---

> ğŸ’¬ *â€œAI Doc Bot â€“ Bringing human-like intelligence to healthcare through voice and vision.â€*
